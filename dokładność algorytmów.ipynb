{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c711e8",
   "metadata": {},
   "source": [
    "Do sprawdzenia dokładności algorytmów wykorzystano dane pochodzą z https://www.kaggle.com/kazanova/sentiment140. Kolumna target zawiera etykiety, które świadczą o wydźwięku danego tweeta: 0 oznacza wydźwięk negatywny, 4 oznacza wydźwięk pozytywny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2157a3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from afinn import Afinn\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1b01ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sentyment140.csv', encoding='latin-1', header=None)\n",
    "df.columns = ['target', 'id', 'date', 'flag', 'user', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2dcc90b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4], dtype=int64)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6a000f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja ktora wyczysci tekst ze zbednych znacznikow\n",
    "def clean(text):\n",
    "    #usunie wszystkie znaki niealfanumeryczne, oprócz alfabetu (az) i cyfr (0-9). Znak ^ oznacza z wyjątkiem.\n",
    "    text_without_symbols = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z'’\\t])|(\\w+:\\/\\/\\S+)\",\" \",text)\n",
    "    regex_pattern = re.compile(pattern = \"[\"\n",
    "        #u\"\\U0001F600-\\U0001F64F\"  # emotikony\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbole i piktogramy\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # symbole transportu i mapy\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flagi\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    # spacja zamiast emotikonow/symboli\n",
    "    text_without_pattern = re.sub(regex_pattern, ' ', text_without_symbols)\n",
    "    \n",
    "    #usuwa linki\n",
    "    link = re.compile(r'(https?://)?(www\\.)?(\\w+\\.)?(\\w+)(\\.\\w+)(/.+)?')\n",
    "    text_without_pattern = re.sub(link, ' ', text_without_pattern)\n",
    "\n",
    "    return text_without_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d2155a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>Awww  that's a bummer   You shoulda got ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>I dived many times for the ball  Managed to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>no  it's not behaving at all  i'm mad  why a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \\\n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...   \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...   \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire    \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                         CleanedText  \n",
       "0        Awww  that's a bummer   You shoulda got ...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2    I dived many times for the ball  Managed to ...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4    no  it's not behaving at all  i'm mad  why a...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CleanedText'] = df['text'].apply(clean)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a559e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Tokenize'] = df['CleanedText'].apply(word_tokenize)\n",
    "df['Tokenize'] = df['CleanedText'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e9b729a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [Awww, that's, a, bummer, You, shoulda, got, D...\n",
       "1          [is, upset, that, he, can't, update, his, Face...\n",
       "2          [I, dived, many, times, for, the, ball, Manage...\n",
       "3          [my, whole, body, feels, itchy, and, like, its...\n",
       "4          [no, it's, not, behaving, at, all, i'm, mad, w...\n",
       "                                 ...                        \n",
       "1599995    [Just, woke, up, Having, no, school, is, the, ...\n",
       "1599996    [TheWDB, com, Very, cool, to, hear, old, Walt,...\n",
       "1599997    [Are, you, ready, for, your, MoJo, Makeover, A...\n",
       "1599998    [Happy, 38th, Birthday, to, my, boo, of, alll,...\n",
       "1599999                              [happy, charitytuesday]\n",
       "Name: Tokenize, Length: 1600000, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tokenize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8155f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        if word not in set(stopwords.words('english')):\n",
    "            newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "    return newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "54c826a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['POS_tagged'] = df['text'].apply(token_stop_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "194214a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "        if not pos:\n",
    "            lemma = word\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "        else:\n",
    "            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew\n",
    "\n",
    "df['Lemma'] = df['POS_tagged'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82523a5",
   "metadata": {},
   "source": [
    "# Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c835d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentyment vader\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_vader_score(sentence): \n",
    "    compound = analyzer.polarity_scores(sentence)['compound']\n",
    "    if compound >= 0: \n",
    "        return 4\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "08c3640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Vader_lemma'] = df.apply(lambda x: get_vader_score(x['Lemma']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9d6bb62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.40      0.53    800000\n",
      "           4       0.60      0.90      0.72    800000\n",
      "\n",
      "    accuracy                           0.65   1600000\n",
      "   macro avg       0.70      0.65      0.63   1600000\n",
      "weighted avg       0.70      0.65      0.63   1600000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# główne metryki klasyfikacji\n",
    "# wartość powinna być jak najbliższa 1.00\n",
    "\n",
    "print(classification_report(df.dropna()[\"target\"].values, df.dropna()[\"Vader_lemma\"].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530fc286",
   "metadata": {},
   "source": [
    "# Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7c3767ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "af = Afinn()\n",
    "df['Afinn_Sentiment_lemma'] = [af.score(i) for i in df['Lemma']]\n",
    "\n",
    "def analysis(score):\n",
    "    if score >= 0:\n",
    "        return 4\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "33ff5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Afinn_lemma\"] = df.apply(lambda x: analysis(x[\"Afinn_Sentiment_lemma\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d810e718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.38      0.52    800000\n",
      "           4       0.59      0.91      0.72    800000\n",
      "\n",
      "    accuracy                           0.64   1600000\n",
      "   macro avg       0.70      0.64      0.62   1600000\n",
      "weighted avg       0.70      0.64      0.62   1600000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.dropna()[\"target\"].values, df.dropna()[\"Afinn_lemma\"].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ad1fd",
   "metadata": {},
   "source": [
    "# TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "88e7f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c6fab386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Textblob_polarity_lemma'] = df['Lemma'].apply(getPolarity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6ee15744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Textblob_lemma\"] = df.apply(lambda x: analysis(x[\"Textblob_polarity_lemma\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f73709ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.29      0.42    800000\n",
      "           4       0.56      0.90      0.69    800000\n",
      "\n",
      "    accuracy                           0.60   1600000\n",
      "   macro avg       0.66      0.60      0.56   1600000\n",
      "weighted avg       0.66      0.60      0.56   1600000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.dropna()[\"target\"].values, df.dropna()[\"Textblob_lemma\"].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfff5a2",
   "metadata": {},
   "source": [
    "# Przeprowadzenie analizy tylko za pomocą -> Clean + Tokenizacja + stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cb1db775",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "df['Text_Ready'] = df['Tokenize'].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c293fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_Ready']= df['Text_Ready'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "880825b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          ['Awww', \"that's\", 'bummer', 'You', 'shoulda',...\n",
       "1          ['upset', \"can't\", 'update', 'Facebook', 'text...\n",
       "2          ['I', 'dived', 'many', 'times', 'ball', 'Manag...\n",
       "3          ['whole', 'body', 'feels', 'itchy', 'like', 'f...\n",
       "4            ['behaving', \"i'm\", 'mad', 'I', \"can't\", 'see']\n",
       "                                 ...                        \n",
       "1599995    ['Just', 'woke', 'Having', 'school', 'best', '...\n",
       "1599996    ['TheWDB', 'com', 'Very', 'cool', 'hear', 'old...\n",
       "1599997    ['Are', 'ready', 'MoJo', 'Makeover', 'Ask', 'd...\n",
       "1599998    ['Happy', '38th', 'Birthday', 'boo', 'alll', '...\n",
       "1599999                          ['happy', 'charitytuesday']\n",
       "Name: Text_Ready, Length: 1600000, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text_Ready']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "aed15693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Vader'] = df.apply(lambda x: get_vader_score(x['Text_Ready']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "24e07aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.39      0.52    800000\n",
      "           4       0.60      0.90      0.72    800000\n",
      "\n",
      "    accuracy                           0.65   1600000\n",
      "   macro avg       0.70      0.65      0.62   1600000\n",
      "weighted avg       0.70      0.65      0.62   1600000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.dropna()[\"target\"].values, df.dropna()[\"Vader\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b5686ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Afinn_Sentiment'] = [af.score(i) for i in df['Text_Ready']]\n",
    "df[\"Afinn\"] = df.apply(lambda x: analysis(x[\"Afinn_Sentiment\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1980028d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.39      0.52    800000\n",
      "           4       0.60      0.90      0.72    800000\n",
      "\n",
      "    accuracy                           0.65   1600000\n",
      "   macro avg       0.70      0.65      0.62   1600000\n",
      "weighted avg       0.70      0.65      0.62   1600000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.dropna()[\"target\"].values, df.dropna()[\"Afinn\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5a9e9aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Textblob_polarity'] = df['Text_Ready'].apply(getPolarity)\n",
    "df[\"Textblob\"] = df.apply(lambda x: analysis(x[\"Textblob_polarity\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6610e340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.30      0.43    800000\n",
      "           4       0.57      0.91      0.70    800000\n",
      "\n",
      "    accuracy                           0.60   1600000\n",
      "   macro avg       0.66      0.60      0.57   1600000\n",
      "weighted avg       0.66      0.60      0.57   1600000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.dropna()[\"target\"].values, df.dropna()[\"Textblob\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c3e8230b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>Tokenize</th>\n",
       "      <th>POS_tagged</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>...</th>\n",
       "      <th>Afinn_Sentiment_lemma</th>\n",
       "      <th>Afinn_lemma</th>\n",
       "      <th>Textblob_polarity_lemma</th>\n",
       "      <th>Textblob_lemma</th>\n",
       "      <th>Text_Ready</th>\n",
       "      <th>Vader</th>\n",
       "      <th>Afinn_Sentiment</th>\n",
       "      <th>Afinn</th>\n",
       "      <th>Textblob_polarity</th>\n",
       "      <th>Textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>Awww  that's a bummer   You shoulda got ...</td>\n",
       "      <td>[Awww, that's, a, bummer, You, shoulda, got, D...</td>\n",
       "      <td>[(@, a), (switchfoot, n), (http, n), (:, None)...</td>\n",
       "      <td>@ switchfoot http : //twitpic.com/2y1zl - Aw...</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>4</td>\n",
       "      <td>['Awww', \"that's\", 'bummer', 'You', 'shoulda',...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>[is, upset, that, he, can't, update, his, Face...</td>\n",
       "      <td>[(upset, a), (ca, None), (n't, r), (update, v)...</td>\n",
       "      <td>upset ca n't update Facebook texting ... mig...</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>['upset', \"can't\", 'update', 'Facebook', 'text...</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>I dived many times for the ball  Managed to ...</td>\n",
       "      <td>[I, dived, many, times, for, the, ball, Manage...</td>\n",
       "      <td>[(@, n), (Kenichan, n), (I, None), (dived, v),...</td>\n",
       "      <td>@ Kenichan I dive many time ball . Managed s...</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>['I', 'dived', 'many', 'times', 'ball', 'Manag...</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>[(whole, a), (body, n), (feels, n), (itchy, v)...</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4</td>\n",
       "      <td>['whole', 'body', 'feels', 'itchy', 'like', 'f...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>no  it's not behaving at all  i'm mad  why a...</td>\n",
       "      <td>[no, it's, not, behaving, at, all, i'm, mad, w...</td>\n",
       "      <td>[(@, a), (nationwideclass, n), (,, None), ('s,...</td>\n",
       "      <td>@ nationwideclass , 's behave . 'm mad . ? I...</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>['behaving', \"i'm\", 'mad', 'I', \"can't\", 'see']</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.6250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>Just woke up  Having no school is the best fee...</td>\n",
       "      <td>[Just, woke, up, Having, no, school, is, the, ...</td>\n",
       "      <td>[(Just, r), (woke, v), (., None), (Having, v),...</td>\n",
       "      <td>Just wake . Having school best feeling ever</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>['Just', 'woke', 'Having', 'school', 'best', '...</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>TheWDB com   Very cool to hear old Walt interv...</td>\n",
       "      <td>[TheWDB, com, Very, cool, to, hear, old, Walt,...</td>\n",
       "      <td>[(TheWDB.com, n), (-, None), (Very, r), (cool,...</td>\n",
       "      <td>TheWDB.com - Very cool hear old Walt intervi...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>4</td>\n",
       "      <td>['TheWDB', 'com', 'Very', 'cool', 'hear', 'old...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2775</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>Are you ready for your MoJo Makeover  Ask me f...</td>\n",
       "      <td>[Are, you, ready, for, your, MoJo, Makeover, A...</td>\n",
       "      <td>[(Are, n), (ready, a), (MoJo, n), (Makeover, n...</td>\n",
       "      <td>Are ready MoJo Makeover ? Ask detail</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4</td>\n",
       "      <td>['Are', 'ready', 'MoJo', 'Makeover', 'Ask', 'd...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time    ...</td>\n",
       "      <td>[Happy, 38th, Birthday, to, my, boo, of, alll,...</td>\n",
       "      <td>[(Happy, a), (38th, None), (Birthday, n), (boo...</td>\n",
       "      <td>Happy 38th Birthday boo alll time ! ! ! Tupa...</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>['Happy', '38th', 'Birthday', 'boo', 'alll', '...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "      <td>happy  charitytuesday</td>\n",
       "      <td>[happy, charitytuesday]</td>\n",
       "      <td>[(happy, a), (#, None), (charitytuesday, a), (...</td>\n",
       "      <td>happy # charitytuesday @ theNSPCC @ SparksCh...</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>4</td>\n",
       "      <td>['happy', 'charitytuesday']</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target          id                          date      flag  \\\n",
       "0             0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1             0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2             0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3             0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4             0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...         ...         ...                           ...       ...   \n",
       "1599995       4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996       4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997       4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998       4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999       4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \\\n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...   \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...   \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire    \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....   \n",
       "...                  ...                                                ...   \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...   \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...   \n",
       "\n",
       "                                               CleanedText  \\\n",
       "0              Awww  that's a bummer   You shoulda got ...   \n",
       "1        is upset that he can't update his Facebook by ...   \n",
       "2          I dived many times for the ball  Managed to ...   \n",
       "3          my whole body feels itchy and like its on fire    \n",
       "4          no  it's not behaving at all  i'm mad  why a...   \n",
       "...                                                    ...   \n",
       "1599995  Just woke up  Having no school is the best fee...   \n",
       "1599996  TheWDB com   Very cool to hear old Walt interv...   \n",
       "1599997  Are you ready for your MoJo Makeover  Ask me f...   \n",
       "1599998  Happy 38th Birthday to my boo of alll time    ...   \n",
       "1599999                       happy  charitytuesday          \n",
       "\n",
       "                                                  Tokenize  \\\n",
       "0        [Awww, that's, a, bummer, You, shoulda, got, D...   \n",
       "1        [is, upset, that, he, can't, update, his, Face...   \n",
       "2        [I, dived, many, times, for, the, ball, Manage...   \n",
       "3        [my, whole, body, feels, itchy, and, like, its...   \n",
       "4        [no, it's, not, behaving, at, all, i'm, mad, w...   \n",
       "...                                                    ...   \n",
       "1599995  [Just, woke, up, Having, no, school, is, the, ...   \n",
       "1599996  [TheWDB, com, Very, cool, to, hear, old, Walt,...   \n",
       "1599997  [Are, you, ready, for, your, MoJo, Makeover, A...   \n",
       "1599998  [Happy, 38th, Birthday, to, my, boo, of, alll,...   \n",
       "1599999                            [happy, charitytuesday]   \n",
       "\n",
       "                                                POS_tagged  \\\n",
       "0        [(@, a), (switchfoot, n), (http, n), (:, None)...   \n",
       "1        [(upset, a), (ca, None), (n't, r), (update, v)...   \n",
       "2        [(@, n), (Kenichan, n), (I, None), (dived, v),...   \n",
       "3        [(whole, a), (body, n), (feels, n), (itchy, v)...   \n",
       "4        [(@, a), (nationwideclass, n), (,, None), ('s,...   \n",
       "...                                                    ...   \n",
       "1599995  [(Just, r), (woke, v), (., None), (Having, v),...   \n",
       "1599996  [(TheWDB.com, n), (-, None), (Very, r), (cool,...   \n",
       "1599997  [(Are, n), (ready, a), (MoJo, n), (Makeover, n...   \n",
       "1599998  [(Happy, a), (38th, None), (Birthday, n), (boo...   \n",
       "1599999  [(happy, a), (#, None), (charitytuesday, a), (...   \n",
       "\n",
       "                                                     Lemma  ...  \\\n",
       "0          @ switchfoot http : //twitpic.com/2y1zl - Aw...  ...   \n",
       "1          upset ca n't update Facebook texting ... mig...  ...   \n",
       "2          @ Kenichan I dive many time ball . Managed s...  ...   \n",
       "3                          whole body feel itchy like fire  ...   \n",
       "4          @ nationwideclass , 's behave . 'm mad . ? I...  ...   \n",
       "...                                                    ...  ...   \n",
       "1599995        Just wake . Having school best feeling ever  ...   \n",
       "1599996    TheWDB.com - Very cool hear old Walt intervi...  ...   \n",
       "1599997               Are ready MoJo Makeover ? Ask detail  ...   \n",
       "1599998    Happy 38th Birthday boo alll time ! ! ! Tupa...  ...   \n",
       "1599999    happy # charitytuesday @ theNSPCC @ SparksCh...  ...   \n",
       "\n",
       "         Afinn_Sentiment_lemma  Afinn_lemma  Textblob_polarity_lemma  \\\n",
       "0                         -2.0            0                 0.216667   \n",
       "1                         -5.0            0                 0.000000   \n",
       "2                          2.0            4                 0.500000   \n",
       "3                         -2.0            0                 0.200000   \n",
       "4                         -3.0            0                -0.625000   \n",
       "...                        ...          ...                      ...   \n",
       "1599995                    4.0            4                 1.000000   \n",
       "1599996                    1.0            4                 0.290000   \n",
       "1599997                    0.0            4                 0.200000   \n",
       "1599998                    3.0            4                 1.000000   \n",
       "1599999                    3.0            4                 0.800000   \n",
       "\n",
       "         Textblob_lemma                                         Text_Ready  \\\n",
       "0                     4  ['Awww', \"that's\", 'bummer', 'You', 'shoulda',...   \n",
       "1                     4  ['upset', \"can't\", 'update', 'Facebook', 'text...   \n",
       "2                     4  ['I', 'dived', 'many', 'times', 'ball', 'Manag...   \n",
       "3                     4  ['whole', 'body', 'feels', 'itchy', 'like', 'f...   \n",
       "4                     0    ['behaving', \"i'm\", 'mad', 'I', \"can't\", 'see']   \n",
       "...                 ...                                                ...   \n",
       "1599995               4  ['Just', 'woke', 'Having', 'school', 'best', '...   \n",
       "1599996               4  ['TheWDB', 'com', 'Very', 'cool', 'hear', 'old...   \n",
       "1599997               4  ['Are', 'ready', 'MoJo', 'Makeover', 'Ask', 'd...   \n",
       "1599998               4  ['Happy', '38th', 'Birthday', 'boo', 'alll', '...   \n",
       "1599999               4                        ['happy', 'charitytuesday']   \n",
       "\n",
       "        Vader  Afinn_Sentiment  Afinn  Textblob_polarity  Textblob  \n",
       "0           0             -2.0      0             0.2000         4  \n",
       "1           0             -5.0      0             0.0000         4  \n",
       "2           4              2.0      4             0.5000         4  \n",
       "3           0             -2.0      0             0.2000         4  \n",
       "4           0             -3.0      0            -0.6250         0  \n",
       "...       ...              ...    ...                ...       ...  \n",
       "1599995     4              4.0      4             1.0000         4  \n",
       "1599996     4              1.0      4             0.2775         4  \n",
       "1599997     4              0.0      4             0.2000         4  \n",
       "1599998     4              3.0      4             0.8000         4  \n",
       "1599999     4              3.0      4             0.8000         4  \n",
       "\n",
       "[1600000 rows x 21 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c668672",
   "metadata": {},
   "source": [
    "# Bez czyszczenia danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fe656bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.43      0.56    800000\n",
      "           4       0.61      0.90      0.73    800000\n",
      "\n",
      "    accuracy                           0.67   1600000\n",
      "   macro avg       0.71      0.67      0.65   1600000\n",
      "weighted avg       0.71      0.67      0.65   1600000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['Vader1'] = df.apply(lambda x: get_vader_score(x['text']), axis=1)\n",
    "print(classification_report(df.dropna()[\"target\"].values, df.dropna()[\"Vader1\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ebb18a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.41      0.54    800000\n",
      "           4       0.60      0.90      0.72    800000\n",
      "\n",
      "    accuracy                           0.65   1600000\n",
      "   macro avg       0.70      0.65      0.63   1600000\n",
      "weighted avg       0.70      0.65      0.63   1600000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['Afinn_Sentiment1'] = [af.score(i) for i in df['text']]\n",
    "df[\"Afinn1\"] = df.apply(lambda x: analysis(x[\"Afinn_Sentiment1\"]), axis=1)\n",
    "print(classification_report(df.dropna()[\"target\"].values, df.dropna()[\"Afinn1\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "60a03ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.32      0.45    800000\n",
      "           4       0.57      0.90      0.70    800000\n",
      "\n",
      "    accuracy                           0.61   1600000\n",
      "   macro avg       0.67      0.61      0.57   1600000\n",
      "weighted avg       0.67      0.61      0.57   1600000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['Textblob_polarity1'] = df['text'].apply(getPolarity)\n",
    "df[\"Textblob1\"] = df.apply(lambda x: analysis(x[\"Textblob_polarity1\"]), axis=1)\n",
    "print(classification_report(df.dropna()[\"target\"].values, df.dropna()[\"Textblob1\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f16018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
